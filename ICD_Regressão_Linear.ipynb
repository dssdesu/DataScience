{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOcM8rYe5dnp"
      },
      "source": [
        "# Tarefa 5 - Regressão Linear e Logística"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_6UuQuIawBM"
      },
      "source": [
        "## Parte 1 - Regressão Linear"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RotuSVCBI2o9"
      },
      "source": [
        "### **Dataset:**\n",
        "\n",
        "Esse dataset contém informações sobre 3000 trabalhadores do sexo masculino na região do Meio-Atlântico dos Estados Unidos. Ele reúne variáveis relacionadas a características demográficas, ocupacionais e salariais, sendo amplamente utilizado em análises de regressão.\n",
        "\n",
        "---\n",
        "\n",
        "**Colunas:**\n",
        "\n",
        "1 - **year** → ano em que as informações salariais foram registradas  \n",
        "\n",
        "2 - **age** → idade do trabalhador  \n",
        "\n",
        "3 - **maritl** → estado civil (1. nunca casado, 2. casado, 3. viúvo, 4. divorciado, 5. separado)  \n",
        "\n",
        "4 - **race** → raça (1. branca, 2. negra, 3. asiática, 4. outra)  \n",
        "\n",
        "5 - **education** → nível educacional (1. < ensino médio, 2. ensino médio, 3. alguma faculdade, 4. graduação, 5. pós-graduação)  \n",
        "\n",
        "6 - **jobclass** → tipo de emprego (1. industrial, 2. informação)  \n",
        "\n",
        "7 - **health** → nível de saúde (1. ≤ bom, 2. ≥ muito bom)  \n",
        "\n",
        "8 - **health_ins** → possui plano de saúde? (1. sim, 2. não)\n",
        "\n",
        "9 - **wage** → salário bruto do trabalhador"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9pqqY5CawBN"
      },
      "source": [
        "### Importação dos Pacotes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHkoFvfS5J_5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, make_scorer\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, make_scorer, confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYmlxs4iawBN"
      },
      "source": [
        "### Carregue a base de dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16diksMbI_h8",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "df_wage = pd.read_csv('wage.csv')\n",
        "display(df_wage)\n",
        "df_wage.info()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7kWehh75J_8"
      },
      "source": [
        "#### Pré-processe a base de dados\n",
        "\n",
        "> Crie listas com o nome das colunas numéricas, categóricas e binárias. Obs.: Não incluir a variável target.\n",
        "\n",
        "> Avalie uma possível remoção de outliers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-PY5L7FJtSA"
      },
      "outputs": [],
      "source": [
        "cols_numericas = ['year', 'age']\n",
        "cols_categoricas = ['maritl', 'race', 'education', 'jobclass', 'health']\n",
        "cols_binarias = ['health_ins']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvngHuiiawBN"
      },
      "source": [
        "> Trate as colunas numéricas com as técnicas aprendidas em aula"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VswV_-BQawBN"
      },
      "outputs": [],
      "source": [
        "for col in cols_numericas:\n",
        "    Q1 = df_wage[col].quantile(0.25)\n",
        "    Q3 = df_wage[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_limite = Q1 - 1.5 * IQR\n",
        "    upper_limite = Q3 + 1.5 * IQR\n",
        "    outliers = df_wage[(df_wage[col] < lower_limite) | (df_wage[col] > upper_limite)]\n",
        "print(f\"Outliers para coluna '{col}':\")\n",
        "display(outliers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Th00u8fpawBO"
      },
      "source": [
        "> Trate as colunas binárias com as técnicas aprendidas em aula."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "n1RnE_EEawBO"
      },
      "outputs": [],
      "source": [
        "df_wage['health_ins'] = df_wage['health_ins'].map({'1. Yes': 1, '2. No': 0})\n",
        "display(df_wage[['health_ins']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYGd_U-VawBO"
      },
      "source": [
        "> Trate as colunas categóricas com as técnicas aprendidas em aula. (lembre-se, para tarefas de regressão linear, é de extrema importância remover uma das categorias de uma coluna categórica para evitar multicolinearidade. Já fizemos isso em exercícios anteriores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "luOSzrJcawBO"
      },
      "outputs": [],
      "source": [
        "df_wage = pd.get_dummies(df_wage, columns=cols_categoricas, drop_first=True)\n",
        "display(df_wage.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOE4M-1MawBO"
      },
      "source": [
        "### Feature Selection\n",
        "\n",
        "> Escolha 3 combinações (subsets) de 4 variáveis do dataset (Obs.: Se selecionar as variaveis (X1, X2, X3, X4) e, por exemplo, X4 é categórica, adicionar todas as colunas geradas após seu tratamento, ex.: (X1, X2, X3, X4_1, X4_2, ...))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yEuvrvN_awBO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_4aQAIbJyRE"
      },
      "source": [
        "### Crie os conjuntos de Treinamento, Teste\n",
        "\n",
        "> Proporção do teste = 33%.\n",
        "\n",
        "> Random state definido para algum valor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kvzvib1X5J_-"
      },
      "outputs": [],
      "source": [
        "X1 = df_wage[['year', 'age', 'maritl_2. Married', 'maritl_3. Widowed', 'maritl_4. Divorced', 'maritl_5. Separated']]\n",
        "X2 = df_wage[['year', 'age', 'race_2. Black', 'race_3. Asian', 'race_4. Other']]\n",
        "X3= df_wage[['year', 'age', 'education_3. Some College', 'education_4. College Grad', 'education_5. Advanced Degree']]\n",
        "\n",
        "y1= df_wage['wage']\n",
        "y2= df_wage['wage']\n",
        "y3= df_wage['wage']\n",
        "\n",
        "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.33, random_state=5521)\n",
        "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.33, random_state=5521)\n",
        "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size=0.33, random_state=5521)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HYln2wl5KAA"
      },
      "source": [
        "### Validação Cruzada\n",
        "\n",
        "> Faça validação cruzada **com 5 folds usando `KFold`**.\n",
        "Defina `shuffle=True` e fixe um `random_state` para reprodutibilidade.\n",
        "\n",
        ">> Avalie, para cada cenário de escolha de *features* (usando os 3 *subsets* definidos e todas as features - 4 cenários), as métricas:\n",
        "- **MSE** (erro quadrático médio),\n",
        "- **MAE** (erro absoluto médio) e\n",
        "- **R²**.\n",
        "\n",
        "> Utilize `cross_val_score` (da scikit-learn) para calcular as métricas em cada fold e **registre a média e o desvio-padrão** de cada métrica por subset em um DataFrame (ou estrutura equivalente).\n",
        "\n",
        "> Observação: para reprodutibilidade, defina algum valor para o parâmetro random_state no StratifiedKFold.\n",
        "\n",
        "> Para cada valor de cenário e para cada métrica, teremos 5 valores diferentes. Sendo assim, guarde em um DataFrame (ou outra estrutura de dado que achar conveniente), a média e o desvio padrão de cada métrica."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8x51yrfHLEEt"
      },
      "outputs": [],
      "source": [
        "model = LinearRegression()\n",
        "scoring = {\n",
        "    'MSE': make_scorer(mean_squared_error),\n",
        "    'MAE': make_scorer(mean_absolute_error),\n",
        "    'R2': make_scorer(r2_score)\n",
        "}\n",
        "\n",
        "cenarios = {\n",
        "    'cenario 1 (Marital Status)': X1,\n",
        "    'cenario 2 (Race)': X2,\n",
        "    'cenario 3 (Education)': X3,\n",
        "    'cenario 4 (Todos Features)': df_wage.drop(['Unnamed: 0', 'wage'], axis=1)\n",
        "}\n",
        "results_df = pd.DataFrame(columns=['Cenario', 'Metrica', 'Media', 'Std'])\n",
        "\n",
        "\n",
        "for scenario_name, X in cenarios.items():\n",
        "    print(f\"Validação Cruzada para: {scenario_name}...\")\n",
        "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "    for metric_name, scorer in scoring.items():\n",
        "        scores = cross_val_score(model, X, df_wage['wage'], cv=kfold, scoring=scorer)\n",
        "        mean_score = scores.mean()\n",
        "        std_dev_score = scores.std()\n",
        "        if metric_name in ['MSE', 'MAE']:\n",
        "             mean_score = abs(mean_score)\n",
        "             std_dev_score = abs(std_dev_score)\n",
        "\n",
        "\n",
        "        results_df = pd.concat([results_df, pd.DataFrame([{\n",
        "            'Cenario': scenario_name,\n",
        "            'Metrica': metric_name,\n",
        "            'Media': mean_score,\n",
        "            'Std': std_dev_score\n",
        "        }])], ignore_index=True)\n",
        "\n",
        "display(results_df)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31199ee7"
      },
      "source": [
        "# Carregar a base de dados novamente para a parte de Regressão Linear\n",
        "df_wage = pd.read_csv('wage.csv')\n",
        "\n",
        "X1 = df_wage[['year', 'age', 'maritl_2. Married', 'maritl_3. Widowed', 'maritl_4. Divorced', 'maritl_5. Separated']]\n",
        "X2 = df_wage[['year', 'age', 'race_2. Black', 'race_3. Asian', 'race_4. Other']]\n",
        "X3= df_wage[['year', 'age', 'education_3. Some College', 'education_4. College Grad', 'education_5. Advanced Degree']]\n",
        "\n",
        "y1= df_wage['wage']\n",
        "y2= df_wage['wage']\n",
        "y3= df_wage['wage']\n",
        "\n",
        "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.33, random_state=5521)\n",
        "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.33, random_state=5521)\n",
        "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size=0.33, random_state=5521)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtpyNQMdLH55"
      },
      "source": [
        "### Escolha do cenário\n",
        "\n",
        "> Escolha o cenário que melhor performou em termos das métricas avaliadas (Não use o R2 como escolha) e justifique.\n",
        "> A partir do cenário escolhido, treine no conjunto de treino com as features do cenário escolhido."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"O cenário escolhido é 'cenario 4 (Todos Features)' devido ao menor MSE e MAE.\")\n",
        "df_wage = pd.read_csv('wage.csv')\n",
        "df_wage['health_ins'] = df_wage['health_ins'].map({'1. Yes': 1, '2. No': 0})\n",
        "cols_categoricas = ['maritl', 'race', 'education', 'jobclass', 'health']\n",
        "df_wage = pd.get_dummies(df_wage, columns=cols_categoricas, drop_first=True)\n",
        "best_scenario_X_train = df_wage.drop(['Unnamed: 0', 'wage'], axis=1).loc[X1_train.index]\n",
        "best_scenario_y_train = y1_train\n",
        "\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(best_scenario_X_train, best_scenario_y_train)\n",
        "\n",
        "print(\"\\nModelo treinado com sucesso no conjunto de treino usando todas as features.\")"
      ],
      "metadata": {
        "id": "GQ4cjP1oO8kO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoAHJz6uawBO"
      },
      "source": [
        "### Avaliação do modelo no conjunto de teste.\n",
        "\n",
        "> Apresente, para o conjunto de teste, como o modelo treinado acima performou em termos das métricas MSE, MAE e R2. Os resultados variaram muito em relação aos obtidos durante a validação cruzada? Discuta."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8c08c8a0"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "best_scenario_X_test = df_wage.drop(['Unnamed: 0', 'wage'], axis=1).loc[X1_test.index]\n",
        "best_scenario_y_test = y1_test\n",
        "\n",
        "y_pred = model.predict(best_scenario_X_test)\n",
        "\n",
        "mse_test = mean_squared_error(best_scenario_y_test, y_pred)\n",
        "mae_test = mean_absolute_error(best_scenario_y_test, y_pred)\n",
        "r2_test = r2_score(best_scenario_y_test, y_pred)\n",
        "\n",
        "print(f\"MSE no conjunto de teste: {mse_test}\")\n",
        "print(f\"MAE no conjunto de teste: {mae_test}\")\n",
        "print(f\"R2 no conjunto de teste: {r2_test}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52a9fda2"
      },
      "source": [
        "**Discussão dos resultados no conjunto de teste:**\n",
        "\n",
        "Compare os valores de MSE, MAE e R2 obtidos no conjunto de teste com as médias e desvios-padrão das métricas do cenário \"cenario 4 (Todos Features)\" na tabela de resultados da validação cruzada (`results_df`). Discuta se os resultados no conjunto de teste variaram muito em relação aos resultados da validação cruzada e o que isso pode indicar sobre a generalização do modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYArfjL7awBO"
      },
      "outputs": [],
      "source": [
        "cv_results_best_scenario = results_df[results_df['Cenario'] == 'cenario 4 (Todos Features)']\n",
        "\n",
        "print(\"Resultados do modelo no conjunto de teste:\")\n",
        "print(f\"MSE: {mse_test}\")\n",
        "print(f\"MAE: {mae_test}\")\n",
        "print(f\"R2: {r2_test}\")\n",
        "\n",
        "print(\"\\nMédia dos resultados da validação cruzada para o cenário 'Todos Features':\")\n",
        "display(cv_results_best_scenario)\n",
        "\n",
        "print(\"Comparando os resultados do conjunto de teste com as médias da validação cruzada:\")\n",
        "print(f\"- MSE no teste ({mse_test:.2f}) vs Média do MSE na validação cruzada ({cv_results_best_scenario[cv_results_best_scenario['Metrica'] == 'MSE']['Media'].iloc[0]:.2f})\")\n",
        "print(f\"- MAE no teste ({mae_test:.2f}) vs Média do MAE na validação cruzada ({cv_results_best_scenario[cv_results_best_scenario['Metrica'] == 'MAE']['Media'].iloc[0]:.2f})\")\n",
        "print(f\"- R2 no teste ({r2_test:.2f}) vs Média do R2 na validação cruzada ({cv_results_best_scenario[cv_results_best_scenario['Metrica'] == 'R2']['Media'].iloc[0]:.2f})\")\n",
        "\n",
        "print(\"\\nA variação entre os resultados do conjunto de teste e a média da validação cruzada é relativamente pequena para todas as métricas (MSE, MAE e R2).\")\n",
        "print(\"Isso sugere que o modelo treinado no conjunto completo de treino (após a validação cruzada) tem uma performance consistente com o que foi observado nos diferentes folds da validação cruzada.\")\n",
        "print(\"Uma pequena variação é esperada devido à aleatoriedade na divisão dos dados, mas uma grande variação poderia indicar problemas como overfitting ou sorte na divisão específica de treino/teste.\")\n",
        "print(\"Neste caso, a similaridade dos resultados indica que o modelo generaliza bem para dados não vistos, o que é um bom sinal.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZKC76OXawBO"
      },
      "source": [
        "Analise os valores do intercepto e dos coeficientes de cada variável usada no treinamento. O que eles têm a dizer?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Analisar o intercepto e os coeficientes do modelo\n",
        "print(\"Intercepto do modelo:\", model.intercept_)\n",
        "print(\"\\nCoeficientes do modelo:\")\n",
        "for feature, coef in zip(best_scenario_X_train.columns, model.coef_):\n",
        "    print(f\"{feature}: {coef}\")"
      ],
      "metadata": {
        "id": "-hwZjhPmO612"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#O intercepto do modelo de regressão linear é aproximadamente -2490.97. Este valor representa o salário médio estimado quando todas as variáveis preditoras são zero.\n",
        "#No contexto deste dataset, onde as variáveis incluem ano, idade e variáveis categóricas transformadas, um intercepto negativo e com esse valor maior pode indicar que\n",
        "#a combinação de todas as variáveis sendo zero pode não ser um cenário realista. Ele serve mais como um ponto de ajuste para a linha de regressão.\n",
        "\n",
        "#as variáveis que parecem ter o maior impacto positivo no salário estimado, com base na magnitude dos coeficientes, são o nível de educação (especialmente pós-graduação),\n",
        "#ter plano de saúde, ser casado e ter saúde considerada \"muito boa ou mais\". As variáveis de raça parecem ter um impacto negativo no salário estimado em comparação com a raça branca.\n",
        "#O ano e a idade também têm efeitos positivos, mas com magnitudes menores do que a educação e o plano de saúde."
      ],
      "metadata": {
        "id": "Y7YbvlwbELV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ln3hKlzJawBP"
      },
      "source": [
        "## Parte 2 - Regressão Logística"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nE6jFpMCawBP"
      },
      "source": [
        "### Importe novamente o dataset wage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Jqe8NInawBP"
      },
      "outputs": [],
      "source": [
        "df_wage = pd.read_csv('wage.csv')\n",
        "display(df_wage)\n",
        "df_wage.info()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFAmrqLvawBP"
      },
      "source": [
        "> Crie uma variável categórica que represente que um salário está acima da média em relação à média desse dataset e, em seguida, remova a coluna `wage`. Queremos 1 para acima da média e 0 para abaixo da média."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwgqDtgPawBP"
      },
      "outputs": [],
      "source": [
        "media_salario = df_wage['wage'].mean()\n",
        "df_wage['wage_above_average'] = (df_wage['wage'] > media_salario).astype(int)\n",
        "df_wage = df_wage.drop('wage', axis=1)\n",
        "display(df_wage.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlEc_c1PawBP"
      },
      "source": [
        "### Pré Processamento e Feature Engineering\n",
        "\n",
        "> Reaproveite todos passos de pré processamento realizados na parte 1 do trabalho (tratamento de outliers, tratamento de variaveis numericas, categoricas, binarias, separação de X e y (agora y é a nova coluna criada),split de treino e teste)\n",
        "\n",
        "> Reaproveite ou crie novos subsets de features, seguindo o passo a passo da parte 1.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "673c30d5"
      },
      "source": [
        "# As colunas 'maritl', 'race', 'education', 'jobclass', 'health' e 'health_ins' já foram tratadas na Parte 1.\n",
        "# Vamos apenas definir X e y e os subsets de features.\n",
        "\n",
        "# Definir X e y para Regressão Logística\n",
        "X = df_wage.drop(['Unnamed: 0', 'wage_above_average'], axis=1)\n",
        "y = df_wage['wage_above_average']\n",
        "\n",
        "# Definir os subsets de features (reaproveitando os da Parte 1, mas com as colunas one-hot encoded)\n",
        "X1 = df_wage[['year', 'age', 'maritl_2. Married', 'maritl_3. Widowed', 'maritl_4. Divorced', 'maritl_5. Separated']]\n",
        "X2 = df_wage[['year', 'age', 'race_2. Black', 'race_3. Asian', 'race_4. Other']]\n",
        "X3 = df_wage[['year', 'age', 'education_2. HS Grad', 'education_3. Some College', 'education_4. College Grad', 'education_5. Advanced Degree']]\n",
        "X_all = X # Todas as features\n",
        "\n",
        "# Criar conjuntos de Treinamento e Teste (reaproveitando a proporção e random_state da Parte 1)\n",
        "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y, test_size=0.33, random_state=5521)\n",
        "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y, test_size=0.33, random_state=5521)\n",
        "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y, test_size=0.33, random_state=5521)\n",
        "X_all_train, X_all_test, y_all_train, y_all_test = train_test_split(X_all, y, test_size=0.33, random_state=5521)\n",
        "\n",
        "print(\"Dados prontos para Regressão Logística.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knIiyGUIawBP"
      },
      "source": [
        "### Validação Cruzada\n",
        "\n",
        "> Faça validação cruzada **com 5 folds usando `StratifiedKFold`**.\n",
        "Defina `shuffle=True` e fixe um `random_state` para reprodutibilidade.\n",
        "\n",
        ">> Avalie, para cada cenário de escolha de *features* (usando os 3 *subsets* definidos e todas as features - 4 cenários), as métricas:\n",
        "- **Acurácia** (erro quadrático médio),\n",
        "- **F1-Score** (erro absoluto médio),\n",
        "- **Recall** e\n",
        "- **Precisão**.\n",
        "\n",
        "> Utilize `cross_val_score` (da scikit-learn) para calcular as métricas em cada fold e **registre a média e o desvio-padrão** de cada métrica por subset em um DataFrame (ou estrutura equivalente).\n",
        "\n",
        "> Para cada valor de cenário e para cada métrica, teremos 5 valores diferentes. Sendo assim, guarde em um DataFrame (ou outra estrutura de dado que achar conveniente), a média e o desvio padrão de cada métrica."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tISQ4F1U5KAB"
      },
      "outputs": [],
      "source": [
        "# Inicializar o modelo de Regressão Logística\n",
        "model_logistica = LogisticRegression(max_iter=1000, random_state=42)\n",
        "\n",
        "# Definir as métricas de scoring para validação cruzada\n",
        "scoring_logistica = {\n",
        "    'Accuracy': make_scorer(accuracy_score),\n",
        "    'F1-Score': make_scorer(f1_score),\n",
        "    'Recall': make_scorer(recall_score),\n",
        "    'Precision': make_scorer(precision_score)\n",
        "}\n",
        "\n",
        "# Definir os cenários de features (reaproveitando as variáveis X preparadas anteriormente)\n",
        "cenarios_logistica = {\n",
        "    'cenario 1 (Marital Status)': X1,\n",
        "    'cenario 2 (Race)': X2,\n",
        "    'cenario 3 (Education)': X3,\n",
        "    'cenario 4 (Todos Features)': X_all # X_all já contém todas as features pré-processadas\n",
        "}\n",
        "\n",
        "# DataFrame para armazenar os resultados\n",
        "results_logistica_df = pd.DataFrame(columns=['Cenario', 'Metrica', 'Media', 'Std'])\n",
        "\n",
        "# Realizar a validação cruzada para cada cenário e métrica\n",
        "for scenario_name, X_scenario in cenarios_logistica.items():\n",
        "    print(f\"Validação Cruzada para: {scenario_name}...\")\n",
        "    # Usar StratifiedKFold para garantir que cada fold tenha a mesma proporção da classe target\n",
        "    kfold_logistica = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "    for metric_name, scorer in scoring_logistica.items():\n",
        "        scores = cross_val_score(model_logistica, X_scenario, y, cv=kfold_logistica, scoring=scorer)\n",
        "        mean_score = scores.mean()\n",
        "        std_dev_score = scores.std()\n",
        "\n",
        "        results_logistica_df = pd.concat([results_logistica_df, pd.DataFrame([{\n",
        "            'Cenario': scenario_name,\n",
        "            'Metrica': metric_name,\n",
        "            'Media': mean_score,\n",
        "            'Std': std_dev_score\n",
        "        }])], ignore_index=True)\n",
        "\n",
        "# Exibir os resultados\n",
        "display(results_logistica_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toVWtOLDawBP"
      },
      "source": [
        "### Escolha do cenário\n",
        "\n",
        "> Escolha o cenário que melhor performou em termos das métricas avaliadas e justifique.\n",
        "> A partir do cenário escolhido, treine no conjunto de treino com as features do cenário escolhido."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8HCYo3DiawBP"
      },
      "outputs": [],
      "source": [
        "# Análise das métricas (Acurácia, F1-Score, Recall, Precision) para escolher o melhor cenário.\n",
        "# O cenário 4 (\"Todos Features\") teve as melhores médias em todas as métricas.\n",
        "\n",
        "print(\"O cenário escolhido para Regressão Logística é 'cenario 4 (Todos Features)' com base nas métricas da validação cruzada.\")\n",
        "\n",
        "# Treinar o modelo de Regressão Logística com o cenário escolhido (todas as features) no conjunto de treino completo\n",
        "model_logistica = LogisticRegression(max_iter=1000, random_state=42)\n",
        "\n",
        "# As variáveis X_all_train e y_all_train já foram criadas na etapa de pré-processamento\n",
        "model_logistica.fit(X_all_train, y_all_train)\n",
        "\n",
        "print(\"\\nModelo de Regressão Logística treinado com sucesso no conjunto de treino usando todas as features.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwz8M_XVawBQ"
      },
      "source": [
        "### Avaliação do modelo no conjunto de teste.\n",
        "\n",
        "> Apresente, para o conjunto de teste, como o modelo treinado acima performou em termos das métricas Acurácia, F1-score, Precisão e recall. Os resultados variaram muito em relação aos obtidos durante a validação cruzada? Discuta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aHyE3wgIawBQ"
      },
      "outputs": [],
      "source": [
        "# Fazer previsões no conjunto de teste\n",
        "y_pred_logistica = model_logistica.predict(X_all_test)\n",
        "\n",
        "# Calcular as métricas de avaliação no conjunto de teste\n",
        "accuracy_test = accuracy_score(y_all_test, y_pred_logistica)\n",
        "f1_test = f1_score(y_all_test, y_pred_logistica)\n",
        "recall_test = recall_score(y_all_test, y_pred_logistica)\n",
        "precision_test = precision_score(y_all_test, y_pred_logistica)\n",
        "\n",
        "print(\"Resultados do modelo de Regressão Logística no conjunto de teste:\")\n",
        "print(f\"Acurácia: {accuracy_test}\")\n",
        "print(f\"F1-Score: {f1_test}\")\n",
        "print(f\"Recall: {recall_test}\")\n",
        "print(f\"Precisão: {precision_test}\")\n",
        "\n",
        "print(\"\\nDiscussão da variação em relação à validação cruzada:\")\n",
        "\n",
        "# Recuperar as médias da validação cruzada para o cenário \"Todos Features\"\n",
        "cv_results_best_scenario_logistica = results_logistica_df[results_logistica_df['Cenario'] == 'cenario 4 (Todos Features)']\n",
        "\n",
        "print(\"Médias dos resultados da validação cruzada para o cenário 'Todos Features':\")\n",
        "display(cv_results_best_scenario_logistica)\n",
        "\n",
        "print(\"\\nComparando os resultados do conjunto de teste com as médias da validação cruzada:\")\n",
        "print(f\"- Acurácia no teste ({accuracy_test:.2f}) vs Média da Acurácia na validação cruzada ({cv_results_best_scenario_logistica[cv_results_best_scenario_logistica['Metrica'] == 'Accuracy']['Media'].iloc[0]:.2f})\")\n",
        "print(f\"- F1-Score no teste ({f1_test:.2f}) vs Média do F1-Score na validação cruzada ({cv_results_best_scenario_logistica[cv_results_best_scenario_logistica['Metrica'] == 'F1-Score']['Media'].iloc[0]:.2f})\")\n",
        "print(f\"- Recall no teste ({recall_test:.2f}) vs Média do Recall na validação cruzada ({cv_results_best_scenario_logistica[cv_results_best_scenario_logistica['Metrica'] == 'Recall']['Media'].iloc[0]:.2f})\")\n",
        "print(f\"- Precisão no teste ({precision_test:.2f}) vs Média da Precisão na validação cruzada ({cv_results_best_scenario_logistica[cv_results_best_scenario_logistica['Metrica'] == 'Precision']['Media'].iloc[0]:.2f})\")\n",
        "\n",
        "print(\"\\nA variação entre os resultados do conjunto de teste e a média da validação cruzada é pequena. Isso indica que o modelo generalizou bem para dados não vistos, e os resultados da validação cruzada foram um bom indicativo da performance esperada.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2fn6eobawBQ"
      },
      "source": [
        "> Apresente a matriz de confusão e discuta os resultados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqYtrlNAawBQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calcular a matriz de confusão\n",
        "cm = confusion_matrix(y_all_test, y_pred_logistica)\n",
        "\n",
        "print(\"Matriz de Confusão:\")\n",
        "display(cm)\n",
        "\n",
        "# Opcional: Visualizar a matriz de confusão\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Abaixo da Média (0)', 'Acima da Média (1)'], yticklabels=['Abaixo da Média (0)', 'Acima da Média (1)'])\n",
        "plt.xlabel('Previsto')\n",
        "plt.ylabel('Real')\n",
        "plt.title('Matriz de Confusão - Regressão Logística')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nDiscussão da Matriz de Confusão:\")\n",
        "print(f\"True Negatives (TN): {cm[0, 0]} - O modelo previu corretamente {cm[0, 0]} casos onde o salário estava abaixo da média.\")\n",
        "print(f\"False Positives (FP): {cm[0, 1]} - O modelo previu incorretamente {cm[0, 1]} casos onde o salário estava acima da média, mas na realidade estava abaixo.\")\n",
        "print(f\"False Negatives (FN): {cm[1, 0]} - O modelo previu incorretamente {cm[1, 0]} casos onde o salário estava abaixo da média, mas na realidade estava acima.\")\n",
        "print(f\"True Positives (TP): {cm[1, 1]} - O modelo previu corretamente {cm[1, 1]} casos onde o salário estava acima da média.\")\n",
        "\n",
        "print(\"\\nAnálise:\")\n",
        "print(f\"O modelo teve uma boa performance em identificar salários abaixo da média (TN = {cm[0, 0]}).\")\n",
        "print(f\"Também conseguiu identificar corretamente uma quantidade razoável de salários acima da média (TP = {cm[1, 1]}).\")\n",
        "print(f\"Os Falsos Positivos ({cm[0, 1]}) indicam que o modelo superestimou o salário em {cm[0, 1]} casos.\")\n",
        "print(f\"Os Falsos Negativos ({cm[1, 0]}) indicam que o modelo subestimou o salário em {cm[1, 0]} casos.\")\n",
        "print(\"A proporção entre Falsos Positivos e Falsos Negativos, juntamente com as métricas de Precision e Recall, ajudam a entender onde o modelo está errando mais.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DJZrZz7awBQ"
      },
      "source": [
        "> Analise os valores do intercepto e dos coeficientes de cada variável usada no treinamento. O que eles têm a dizer?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oq5F5dzaawBQ"
      },
      "outputs": [],
      "source": [
        "# Analisar os coeficientes do modelo de Regressão Logística\n",
        "print(\"Intercepto do modelo de Regressão Logística:\", model_logistica.intercept_)\n",
        "print(\"\\nCoeficientes do modelo de Regressão Logística:\")\n",
        "for feature, coef in zip(X_all_train.columns, model_logistica.coef_[0]):\n",
        "    print(f\"{feature}: {coef}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_n9a7PRawBQ"
      },
      "outputs": [],
      "source": [
        "#Na Regressão Logística, os coeficientes representam a mudança no log-odds da variável dependente (salário acima da média) para cada aumento de uma unidade na variável preditora, mantendo\n",
        "#as outras variáveis constantes. A relação entre log-odds e probabilidade é sigmoidal.\n",
        "#Um coeficiente positivo indica que a variável preditora aumenta a probabilidade de o salário estar acima da média, enquanto um coeficiente negativo indica que a variável diminui essa probabilidade.\n",
        "#O intercepto representa o log-odds de o salário estar acima da média quando todas as variáveis preditoras são zero.\n",
        "\n",
        "#os coeficientes indicam que variáveis como ter plano de saúde, estado civil (especialmente ser casado), nível de educação (quanto maior, maior o impacto positivo),\n",
        "#estar na classe de trabalho 'Informação' e ter melhor saúde estão positivamente associadas à probabilidade de ter um salário acima da média.\n",
        "#Variáveis como raça (exceto asiática, com pequeno impacto positivo) parecem estar negativamente associadas."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}